{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-14T17:25:47.302743Z","iopub.execute_input":"2023-05-14T17:25:47.303150Z","iopub.status.idle":"2023-05-14T17:25:47.324550Z","shell.execute_reply.started":"2023-05-14T17:25:47.303119Z","shell.execute_reply":"2023-05-14T17:25:47.323831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np  \nimport pandas as pd\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:25:47.325925Z","iopub.execute_input":"2023-05-14T17:25:47.326752Z","iopub.status.idle":"2023-05-14T17:25:54.982346Z","shell.execute_reply.started":"2023-05-14T17:25:47.326722Z","shell.execute_reply":"2023-05-14T17:25:54.981310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Set","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/fer2013/fer2013.csv')\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:25:54.983470Z","iopub.execute_input":"2023-05-14T17:25:54.984030Z","iopub.status.idle":"2023-05-14T17:26:00.857600Z","shell.execute_reply.started":"2023-05-14T17:25:54.984000Z","shell.execute_reply":"2023-05-14T17:26:00.856653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:00.859792Z","iopub.execute_input":"2023-05-14T17:26:00.860103Z","iopub.status.idle":"2023-05-14T17:26:00.888846Z","shell.execute_reply.started":"2023-05-14T17:26:00.860075Z","shell.execute_reply":"2023-05-14T17:26:00.887921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#80% training, 10% validation and 10% testing\ndata.Usage.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:00.889902Z","iopub.execute_input":"2023-05-14T17:26:00.890184Z","iopub.status.idle":"2023-05-14T17:26:00.902252Z","shell.execute_reply.started":"2023-05-14T17:26:00.890157Z","shell.execute_reply":"2023-05-14T17:26:00.901348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Emotion Category\nemotion_map = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nemotion_counts = data['emotion'].value_counts().sort_index().reset_index()\nemotion_counts.columns = ['emotion', 'number']\nemotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\nemotion_counts","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:00.903306Z","iopub.execute_input":"2023-05-14T17:26:00.903594Z","iopub.status.idle":"2023-05-14T17:26:00.925186Z","shell.execute_reply.started":"2023-05-14T17:26:00.903567Z","shell.execute_reply":"2023-05-14T17:26:00.924262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Emotion Category Distribution\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize=(6, 4))\nsns.barplot(x=emotion_counts.emotion, y=emotion_counts.number)\nplt.title('Class distribution')\nplt.ylabel('Number', fontsize=12)\nplt.xlabel('Emotions', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:00.926614Z","iopub.execute_input":"2023-05-14T17:26:00.926959Z","iopub.status.idle":"2023-05-14T17:26:01.174294Z","shell.execute_reply.started":"2023-05-14T17:26:00.926930Z","shell.execute_reply":"2023-05-14T17:26:01.173037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image sample\ndef row2image_label(row):\n    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n    img = np.array(pixels.split())\n    img = img.reshape(48, 48)\n    image = np.zeros((48, 48, 3))\n    image[:, :, 0] = img\n    image[:, :, 1] = img\n    image[:, :, 2] = img\n    return image.astype(np.uint8), emotion\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(0, figsize=(16, 10))\nfor i in range(1, 8):\n    face = data[data['emotion'] == i - 1].iloc[0]\n    img, label = row2image_label(face)\n    plt.subplot(2, 4, i)\n    plt.imshow(img)\n    plt.title(label)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:01.175945Z","iopub.execute_input":"2023-05-14T17:26:01.176460Z","iopub.status.idle":"2023-05-14T17:26:02.412640Z","shell.execute_reply.started":"2023-05-14T17:26:01.176420Z","shell.execute_reply":"2023-05-14T17:26:02.411647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocess","metadata":{}},{"cell_type":"code","source":"# Data Split\ndata_train = data[data['Usage'] == 'Training'].copy()\ndata_val = data[data['Usage'] == 'PublicTest'].copy()\ndata_test = data[data['Usage'] == 'PrivateTest'].copy()\nprint(f\"train shape: {data_train.shape}\")\nprint(f\"validation shape: {data_val.shape}\")\nprint(f\"test shape: {data_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:02.414225Z","iopub.execute_input":"2023-05-14T17:26:02.415244Z","iopub.status.idle":"2023-05-14T17:26:02.436802Z","shell.execute_reply.started":"2023-05-14T17:26:02.415205Z","shell.execute_reply":"2023-05-14T17:26:02.435686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, val, test distribution\nemotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\n\ndef setup_axe(axe, df, title):\n    df['emotion'].value_counts().sort_index().plot(ax=axe, kind='bar', rot=0,\n                                                   color=['r', 'g', 'b', 'r', 'g', 'b', 'r'])\n    axe.set_xticklabels(emotion_labels)\n    axe.set_xlabel(\"Emotions\")\n    axe.set_ylabel(\"Number\")\n    axe.set_title(title)\n\n    for i in axe.patches:\n        # get_x pulls left or right; get_height pushes up or down\n        axe.text(i.get_x() - .05, i.get_height() + 120,\n                 str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',\n                 rotation=0)\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nfig, axes = plt.subplots(1, 3, figsize=(20, 8), sharey='all')\nsetup_axe(axes[0], data_train, 'Train')\nsetup_axe(axes[1], data_val, 'Validation')\nsetup_axe(axes[2], data_test, 'Test')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:02.440957Z","iopub.execute_input":"2023-05-14T17:26:02.441310Z","iopub.status.idle":"2023-05-14T17:26:03.119893Z","shell.execute_reply.started":"2023-05-14T17:26:02.441282Z","shell.execute_reply":"2023-05-14T17:26:03.118945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters Initialization\nnum_classes = 7\nwidth, height = 48, 48\nnum_epochs = 300\nbatch_size = 128\nnum_features = 64\nrate_drop = 0.1","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:03.120969Z","iopub.execute_input":"2023-05-14T17:26:03.121252Z","iopub.status.idle":"2023-05-14T17:26:03.126727Z","shell.execute_reply.started":"2023-05-14T17:26:03.121227Z","shell.execute_reply":"2023-05-14T17:26:03.125855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CRNO -- Convert, Reshape, Normalize, One-hot encoding\n# 1. Change the data labels from string to integer\n# 2. Resize the images to 48x48, normalize them\n# 3. one-hot encoding \n# e.g. category 3(Happy) to [0,0,0,1,0,0,0]\n\ndef CRNO(df, dataName):\n    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1, width, height, 1) / 255.0\n    data_Y = to_categorical(df['emotion'], num_classes)\n    print(dataName, f\"_X shape: {data_X.shape}, \", dataName, f\"_Y shape: {data_Y.shape}\")\n    return data_X, data_Y\n\n\ntrain_X, train_Y = CRNO(data_train, \"train\")  #training data\nval_X, val_Y = CRNO(data_val, \"val\")  #validation data\ntest_X, test_Y = CRNO(data_test, \"test\")  #test data","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:03.128137Z","iopub.execute_input":"2023-05-14T17:26:03.128458Z","iopub.status.idle":"2023-05-14T17:26:26.138051Z","shell.execute_reply.started":"2023-05-14T17:26:03.128424Z","shell.execute_reply":"2023-05-14T17:26:26.136981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\n# ---------- Convolutional Stages 1 ----------\n# ***** Conv Block a *****\nmodel.add(Conv2D(64, kernel_size=(3, 3), input_shape=(width, height, 1),\n                 data_format='channels_last', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# ***** Conv Block b *****\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# max pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# ---------- Convolutional Stages 2 ----------\n# ***** Conv Block a *****\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# ***** Conv Block b *****\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# max pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# ---------- Convolutional Stages 3 ----------\n# ***** Conv Block a *****\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# ***** Conv Block b *****\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# max pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# ---------- Convolutional Stages 4 ----------\n# ***** Conv Block a *****\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# ***** Conv Block b *****\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# max pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten\nmodel.add(Flatten())\n\n# Full connection\nmodel.add(Dense(4096, activation='relu', kernel_regularizer=l2()))\nmodel.add(Dropout(rate_drop))\nmodel.add(Dense(4096, activation='relu', kernel_regularizer=l2()))\nmodel.add(Dropout(rate_drop))\n\n#output layer\nmodel.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2()))\n\nmodel.compile(loss=['categorical_crossentropy'],\n              optimizer=SGD(momentum=0.9, nesterov=True ,learning_rate=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:26.139574Z","iopub.execute_input":"2023-05-14T17:26:26.140125Z","iopub.status.idle":"2023-05-14T17:26:27.037039Z","shell.execute_reply.started":"2023-05-14T17:26:26.140086Z","shell.execute_reply":"2023-05-14T17:26:27.035982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation & Model Fitting","metadata":{}},{"cell_type":"code","source":"# Use ImageDataGenerator in Keras to do data augmentation\ndata_generator = ImageDataGenerator(\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    rotation_range=10,\n    featurewise_std_normalization=False,\n    horizontal_flip=True)\n\n# Monitor val_loss, if there is no less value loss, stop training early to prevent overfitting\nes = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n\n# Monitor val_accuracy, if there is no higher value accuracy, lower the learning rate\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.75, patience=5, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:27.038629Z","iopub.execute_input":"2023-05-14T17:26:27.038971Z","iopub.status.idle":"2023-05-14T17:26:27.044826Z","shell.execute_reply.started":"2023-05-14T17:26:27.038941Z","shell.execute_reply":"2023-05-14T17:26:27.043831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\nelse:\n    print(\"No GPU devices found.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:27.046457Z","iopub.execute_input":"2023-05-14T17:26:27.046850Z","iopub.status.idle":"2023-05-14T17:26:27.057610Z","shell.execute_reply.started":"2023-05-14T17:26:27.046817Z","shell.execute_reply":"2023-05-14T17:26:27.056640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(data_generator.flow(train_X, train_Y, batch_size),\n                    # steps_per_epoch=len(train_X) / batch_size,\n                    batch_size=batch_size,\n                    epochs=num_epochs,\n                    verbose=2,\n                    callbacks=[es, reduce_lr],\n                    validation_data=(val_X, val_Y))","metadata":{"execution":{"iopub.status.busy":"2023-05-14T17:26:27.059078Z","iopub.execute_input":"2023-05-14T17:26:27.059361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\n# Training and Validation Accuracy\naxes[0].plot(history.history['accuracy'])\naxes[0].plot(history.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Training and Validation Loss\naxes[1].plot(history.history['loss'])\naxes[1].plot(history.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T14:04:49.195496Z","iopub.execute_input":"2023-05-15T14:04:49.195893Z","iopub.status.idle":"2023-05-15T14:04:49.612680Z","shell.execute_reply.started":"2023-05-15T14:04:49.195861Z","shell.execute_reply":"2023-05-15T14:04:49.609741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model.predict(test_X), axis=1)\nprint(\"CNN Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Print Confusion Matrix\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Calculation\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the label in the data\n    classes = classes\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n    #print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # Show labels\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # rotate x labels\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop through the data dimensions and create text annotations\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","metadata":{},"execution_count":null,"outputs":[]}]}